{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Assignment No 2\n",
    "----\n",
    "## i160061_SecA_Decision_Tree\n",
    "## Goal\n",
    "\n",
    "Your goal in this assigment is to implement a Decision Tree Classifier.\n",
    "\n",
    "**Note** Please note that you are allowed to use only those libraries which we have discussed in the class, i.e. numpy, scipy, pandas. You can use scikit-learn only for data splitting.\n",
    "\n",
    "## Submission Instructions\n",
    "You are required to submit the original notebook file on the Classsroom (with .ipynb extension), with complete set of outputs. Students failing to do so will get zero marks. \n",
    "\n",
    "*Please read each step carefully and understand it fully before proceeding with code writing*\n",
    "\n",
    "## Plagiarism\n",
    "Any form of plagiarism will not be tolerated and result in 0 marks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "Now in this assignment we will be implementing the Decision Classifier for Continuous attributes.\n",
    "\n",
    "You will be testing your implementations with only one split criteria, namely:\n",
    " - Information Gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict  # default dictionary \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5f673a73f08c6a76dd52953330389488",
     "grade": false,
     "grade_id": "node",
     "locked": false,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,purity,classlabel='',score=0,split=[],fidx=-1):\n",
    "        self.lchild=None       \n",
    "        self.rchild=None\n",
    "        self.classlabel=classlabel        \n",
    "        self.split=split\n",
    "        self.score=score #MinEntropy\n",
    "        self.fidx=fidx #feature index\n",
    "        self.purity=purity #purity\n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        # YOUR CODE HERE\n",
    "        self.lchild=lchild\n",
    "        self.rchild=rchild\n",
    "        \n",
    "    def isleaf(self):\n",
    "        # YOUR CODE HERE\n",
    "        if self.lchild==None and self.rchild==None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "    def isless_than_eq(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.classlabel,self.purity)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A placeholder class \n",
    "# TODO: You have to implement the following class, remember from the lectures that you will \n",
    "# need to build a model for each different class you are trying to identify..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "823ecf560a3fef28b50be423ab4fd6a5",
     "grade": false,
     "grade_id": "tree",
     "locked": false,
     "solution": true
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Your code goes here...\n",
    "# You might need to define  classes for composition.. ?\n",
    "class DecisionTree:\n",
    "    ''' Implements the Decision Tree For Classification... \n",
    "        '''\n",
    "    def __init__(self, purityp, exthreshold,maxdepth=10):        \n",
    "        self.purity=purityp\n",
    "        self.exthreshold=exthreshold #minimun no of examples threshold \n",
    "        self.maxdepth=maxdepth\n",
    "        pass\n",
    "    def train(self, X, Y):\n",
    "        ''' Train Decision Tree using the given \n",
    "            X [m x d] data matrix and Y labels matrix\n",
    "            \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns:\n",
    "            -----------\n",
    "            Nothing\n",
    "            '''\n",
    "        \n",
    "        nexamples,nfeatures=X.shape\n",
    "        ## now go and train a model for each class...\n",
    "        # YOUR CODE HERE\n",
    "        depth=0 \n",
    "        self.tree = self.build_tree(X,Y,0)\n",
    "        \n",
    "        \n",
    "    def build_tree(self, X, Y, depth):\n",
    "        # YOUR CODE HERE\n",
    "        feat_size,total_features = X.shape\n",
    "        classes = np.unique(Y) #unique classes in dataset\n",
    "        p_i = np.zeros(classes.size) #to save purity of each class\n",
    "        for i in range(p_i.shape[0]):\n",
    "            p_i[i] = Y[Y==classes[i]].shape[0]/Y.shape[0]\n",
    "        max_purity_class = np.argmax(p_i) #class which purity is max\n",
    "        max_purity = np.max(p_i) #purity of that class\n",
    "        newNode = Node(0)\n",
    "        #base case\n",
    "        if(max_purity>=self.purity or feat_size <=self.exthreshold or depth >=self.maxdepth):\n",
    "            newNode.purity = max_purity\n",
    "            newNode.classlabel = classes[max_purity_class]\n",
    "            return newNode\n",
    "        else:\n",
    "            b_split_point = np.inf\n",
    "            b_score = np.inf\n",
    "            b_feat = -1\n",
    "            for i in range(total_features):\n",
    "                _split ,_entropy = self.evaluate_numerical_attribute(X[:,i],Y)\n",
    "                if(_entropy<b_score):\n",
    "                    b_score = _entropy\n",
    "                    b_split_point = _split\n",
    "                    b_feat = i\n",
    "            #split data on basis of b_split point\n",
    "            b_split_left_idx = X[:,b_feat]<b_split_point\n",
    "            b_split_right_idx = X[:,b_feat]>=b_split_point\n",
    "            \n",
    "            X_left = X[b_split_left_idx]\n",
    "            X_Right = X[b_split_right_idx]\n",
    "            Y_Left = Y[b_split_left_idx]\n",
    "            Y_Right = Y[b_split_right_idx]\n",
    "            \n",
    "            newNode.fidx = b_feat\n",
    "            newNode.score = b_score\n",
    "            newNode.split = b_split_point\n",
    "            newNode.lchild = self.build_tree(X_left,Y_Left,depth+1)\n",
    "            newNode.rchild = self.build_tree(X_Right,Y_Right,depth+1)\n",
    "            return newNode\n",
    "        pass\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Test the trained classifiers on the given set of examples \n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional test examples.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for each example, i.e. to which it belongs\n",
    "        '''\n",
    "        nexamples, nfeatures=X.shape\n",
    "        pclasses=self.predict(X)\n",
    "        return np.array(pclasses)\n",
    "        pass\n",
    "    \n",
    "    def evaluate_numerical_attribute(self,features, Y):\n",
    "        classes = np.unique(Y)\n",
    "        nClasses = classes.shape[0]\n",
    "        sIdx = np.argsort(features)   #sorted index of feature\n",
    "        nY = np.zeros(Y.shape[0])     #numerical label\n",
    "        \n",
    "        for i in range(len(classes)):\n",
    "            nY[Y==classes[i]] = i\n",
    "        sFeat = features[sIdx]        #sorted features\n",
    "        sY = nY[sIdx]                 #sorted labels\n",
    "        \n",
    "        mid_points = (sFeat[1:]+sFeat[:-1])/2 #get midpoint of all examples\n",
    "        \n",
    "        IG = []\n",
    "        \n",
    "        for mid_point in mid_points:\n",
    "            featLM = sFeat[sFeat<mid_point] #feature less then ith midpoint\n",
    "            labelLM = sY[0:featLM.shape[0]] # and there labels\n",
    "            \n",
    "            featGEM = sFeat[sFeat>=mid_point] #feature greater or equal ith midpoint\n",
    "            labelGEM = sY[featLM.shape[0]:] # and there labels\n",
    "            \n",
    "            pi_l ,pi_r,e_l,e_r = 0,0,0,0\n",
    "            for i in range(nClasses):\n",
    "                if(labelLM.shape[0]!=0):\n",
    "                    pi_l = labelLM[labelLM==i].shape[0]/labelLM.shape[0] #prob of feature at left i.e <midpoint\n",
    "                if(pi_l!=0):    \n",
    "                    e_l += pi_l * np.log2(pi_l) #entropy  of feature\n",
    "                 \n",
    "                if(labelGEM.shape[0]!=0):\n",
    "                    pi_r = labelGEM[labelGEM==i].shape[0]/labelGEM.shape[0]\n",
    "                if(pi_r!=0):\n",
    "                    e_r += pi_r * np.log2(pi_r)\n",
    "                \n",
    "               # print(\"i:\",i,\"-->PL:\",pi_l,\"PR\",pi_r)\n",
    "            \n",
    "            e_l = -1*e_l\n",
    "            e_r = -1*e_r\n",
    "            \n",
    "            p_l = featLM.shape[0]/features.shape[0]\n",
    "            p_r = featGEM.shape[0]/features.shape[0]\n",
    "            \n",
    "            child_entropy = p_l*e_l + p_r*e_r\n",
    "            IG.append(child_entropy)\n",
    "        parent_entropy = 0\n",
    "        for i in range(nClasses):\n",
    "            parent_entropy += ((sY[sY==i].shape[0]/sY.shape[0])*np.log2((sY[sY==i].shape[0])/sY.shape[0]))\n",
    "        parent_entropy = -parent_entropy\n",
    "        \n",
    "        minEntropy = np.min(IG)\n",
    "        iMin = np.argmin(IG)\n",
    "       # print(parent_entropy-IG)\n",
    "        return mid_points[iMin], minEntropy+1.0e-20\n",
    "           \n",
    "    def predict(self, X):\n",
    "        predicted=[]\n",
    "        for i in range(X.shape[0]):\n",
    "            predicted.append(self._predict(self.tree,X[i,:]))\n",
    "        return np.array(predicted) \n",
    "        \n",
    "    def _predict(self,node, X):\n",
    "        if node.isleaf():\n",
    "            return node.classlabel\n",
    "        elif X[node.fidx] >= node.split:\n",
    "            return self._predict(node.rchild, X)\n",
    "        else:\n",
    "            return self._predict(node.lchild, X)\n",
    "    def __str__(self):\n",
    "        \n",
    "        return self.__print(self.tree)        \n",
    "        \n",
    "     \n",
    "    def find_depth(self):\n",
    "        return self._find_depth(self.tree)\n",
    "    \n",
    "    \n",
    "    def _find_depth(self,node):\n",
    "        if not node:\n",
    "            return\n",
    "        if node.isleaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return max(self._find_depth(node.lchild),self._find_depth(node.rchild))+1\n",
    "    def __print(self,node,depth=0):\n",
    "        \n",
    "        ret = \"\"\n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "        # Print right branch\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild,depth+1)\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild,depth+1)        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the first case here, you are asked to train on all the data using only two features and classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "count   149.000000  149.000000   149.000000  149.000000\n",
      "mean      5.848322    3.051007     3.774497    1.205369\n",
      "std       0.828594    0.433499     1.759651    0.761292\n",
      "min       4.300000    2.000000     1.000000    0.100000\n",
      "25%       5.100000    2.800000     1.600000    0.300000\n",
      "50%       5.800000    3.000000     4.400000    1.300000\n",
      "75%       6.400000    3.300000     5.100000    1.800000\n",
      "max       7.900000    4.400000     6.900000    2.500000\n"
     ]
    }
   ],
   "source": [
    "#load the data set\n",
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (149, 4)  True Class labels dimensions (149,)\n"
     ]
    }
   ],
   "source": [
    "# Get your data in matrix\n",
    "X=np.asarray(data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y=np.asarray(data['Class'].dropna())\n",
    "print (\" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here data is being set so that there are only two classes\n",
    "Y[Y=='Iris-virginica']='Iris-versicolor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.45 0.3887071918248902\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feat=[0,1] # because we are only using two features in the beginning\n",
    "dt=DecisionTree(0.95,5,50)\n",
    "dt.classes=np.unique(Y)\n",
    "dt.nclasses=len(np.unique(Y))\n",
    "split,mingain=dt.evaluate_numerical_attribute(X[:,0],Y)\n",
    "print (split,mingain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d3e8e586dd07a46aa77945942d370783",
     "grade": true,
     "grade_id": "split_gain",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_almost_equal, assert_equal\n",
    "\n",
    "assert_equal(split, 5.45)\n",
    "assert_almost_equal(mingain, 0.38, places=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.train(X[:,feat],Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I(Fidx=0,Score=0.3887071918248902,Split=5.45)\n",
      "    I(Fidx=1,Score=0.07791297983060938,Split=3.45)\n",
      "        I(Fidx=0,Score=1e-20,Split=6.5)\n",
      "            C(class=Iris-versicolor,Purity=1.0)\n",
      "            C(class=Iris-setosa,Purity=1.0)\n",
      "        C(class=Iris-versicolor,Purity=1.0)\n",
      "    I(Fidx=1,Score=0.21622188662602276,Split=2.8)\n",
      "        C(class=Iris-setosa,Purity=0.9772727272727273)\n",
      "        I(Fidx=0,Score=1e-20,Split=4.7)\n",
      "            C(class=Iris-versicolor,Purity=1.0)\n",
      "            C(class=Iris-setosa,Purity=1.0)\n"
     ]
    }
   ],
   "source": [
    "print (dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print( dt.find_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XY_Train_Test(X,Y,training_probabilty,random=True):\n",
    "    no_of_columns = np.shape(X)[1]\n",
    "    no_of_rows = np.shape(X)[0]\n",
    "    traning_data_size =int(no_of_rows*training_probabilty)\n",
    "    temp = np.arange(0,no_of_rows)\n",
    "    X_Train,Y_Train = np.zeros((traning_data_size,no_of_columns)),np.zeros(traning_data_size,dtype = Y.dtype)\n",
    "    X_Test,Y_Test = np.zeros((no_of_rows-traning_data_size,no_of_columns)),np.zeros(no_of_rows-traning_data_size,dtype = Y.dtype)\n",
    "    if(random):\n",
    "        np.random.shuffle(temp)\n",
    "    X_Train[0:traning_data_size] = X[temp[0:traning_data_size],]\n",
    "    X_Test[0:no_of_rows-traning_data_size] = X[temp[traning_data_size:no_of_rows],]\n",
    "    Y_Train[0:traning_data_size] = Y[temp[0:traning_data_size]]\n",
    "    Y_Test[0:no_of_rows-traning_data_size] = Y[temp[traning_data_size:no_of_rows]]\n",
    "    return X_Train,Y_Train,X_Test,Y_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (104, 4) Training True Class labels dimensions (104,)\n",
      " Test Data Set Dimensions= (45, 4) Test True Class labels dimensions (45,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set...\n",
    "Xtrain,Ytrain,Xtest,Ytest = XY_Train_Test(X,Y,.7)\n",
    "print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape   )\n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytest.shape   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "pclasses = dt.test(Xtest)\n",
    "print (np.sum(pclasses==Ytest))\n",
    "print (\"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5,10)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.test(Xtest[:,feat])\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a67690827399cc59eead882a1cc823fc",
     "grade": true,
     "grade_id": "two_features",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.test(Xtest[:,feat])\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "print(acc)\n",
    "assert_greater_equal(acc, 0.90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train on all four features...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "#Lets Train on all four features....\n",
    "\n",
    "# Lets train a Decision Tree Classifier on Petal Length and Width\n",
    "feat=[0, 1, 2, 3]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.test(Xtest[:,feat])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print (np.sum(pclasses==Ytest))\n",
    "print (\"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train on all four features and for all three classes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (149, 4)  True Class labels dimensions (149,)\n"
     ]
    }
   ],
   "source": [
    "X=np.asarray(data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y=np.asarray(data['Class'].dropna())\n",
    "print (\" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (104, 4) Training True Class labels dimensions (104,)\n",
      " Test Data Set Dimensions= (45, 4) Test True Class labels dimensions (45,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest = XY_Train_Test(X,Y,.7)\n",
    "print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape   )\n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytest.shape   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Accuracy =  0.6444444444444445\n"
     ]
    }
   ],
   "source": [
    "feat=[0, 1,2,3]\n",
    "dt=DecisionTree(0.95,5,50)\n",
    "good=[0,1]\n",
    "dt.train(Xtrain[:,good],Ytrain)\n",
    "pclasses=dt.test(Xtest[:,good])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print( np.sum(pclasses==Ytest))\n",
    "print (\"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "972ca9bb1ffa85dd250fb9b790bca865",
     "grade": true,
     "grade_id": "all_features",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "\n",
    "feat=[0, 1, 2, 3]\n",
    "dt=DecisionTree(0.95,5)\n",
    "good=[0,1]\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.test(Xtest[:,feat])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "print(acc)\n",
    "assert_greater_equal(acc, 0.90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What can you conclude ?\n",
    "====================\n",
    "Please write your observation....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## with 2 features and 2 label the accuracy is 91 percent\n",
    "## with 2 feature and 3 label the accuracy is 77 percent\n",
    "## with 4 feature and 2 label accuracy is 100 percent\n",
    "## with 4 feature and 3 label accuracy is 91 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
